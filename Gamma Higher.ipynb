{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gamma higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import egttools as egt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the pay-off matrix\n",
    "## The reward values (prisoner's dilemma)\n",
    "R_pd = 1\n",
    "S_pd = -1\n",
    "T_pd = 2\n",
    "P_pd = 0\n",
    "## The reward values (snowdrift)\n",
    "R_sd = 1\n",
    "S_sd = 0\n",
    "T_sd = 2\n",
    "P_sd = -1\n",
    "## The values used to calculate the reward for a certain strategy\n",
    "gamma = 1 # Importance of the game\n",
    "r = 50 # number of rounds\n",
    "theta = 3 # trust threshold\n",
    "p = 0.25 # Chance of checking\n",
    "epsilon = 0.25 # opportunity cost\n",
    "# Parameters for the game settings\n",
    "beta = 0.1 # intensity of selection\n",
    "Z = 100 # Population size (N)\n",
    "mu = 0 # the mutation probability\n",
    "nb_strategies_with = 5 # The amount of strategies\n",
    "strategies = [\"ALLC\",\"ALLD\",\"TFT\",\"TUC\",\"TUD\"] # The name of each strategy\n",
    "colors_strat = [\"tab:blue\",\"tab:orange\",\"tab:green\",\"tab:red\",\"tab:purple\"] # the color for each strategy\n",
    "nb_strategies_without = 3 # the amount of strategies without TUC and TUD\n",
    "colors_trust = [\"tab:orange\",\"tab:blue\"] # The color for the frequency of trust\n",
    "# boolean to run smaller experiments seperatly\n",
    "run_small = True\n",
    "run_big = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pay_off(R,S,T,P,gamma,r,theta,p,epsilon):\n",
    "    # Multiply the rewards with the importance of the game\n",
    "    R *= gamma\n",
    "    S *= gamma\n",
    "    T *= gamma\n",
    "    P *= gamma\n",
    "    # Calculate the value of each strategy\n",
    "    # static table\n",
    "    ## Always cooperate (ALLC)\n",
    "    ALLC_ALLC = R\n",
    "    ALLC_ALLD = S\n",
    "    ALLC_TFT = R\n",
    "    ALLC_TUC = R\n",
    "    ALLC_TUD = (theta*R+(r-theta)*S)/r\n",
    "    ALLC = [ALLC_ALLC,ALLC_ALLD,ALLC_TFT,ALLC_TUC,ALLC_TUD]\n",
    "    ## Always defect (ALLD)\n",
    "    ALLD_ALLC = T\n",
    "    ALLD_ALLD = P\n",
    "    ALLD_TFT = (T+(r-1)*P)/r\n",
    "    ALLD_TUC = (T+(r-1)*P)/r\n",
    "    ALLD_TUD = (T+(r-1)*P)/r\n",
    "    ALLD = [ALLD_ALLC,ALLD_ALLD,ALLD_TFT,ALLD_TUC,ALLD_TUD]\n",
    "    ## Tit for Tat (TFT)\n",
    "    TFT_ALLC = R-epsilon\n",
    "    TFT_ALLD = (S+(r-1)*P)/r - epsilon\n",
    "    TFT_TFT = R - epsilon\n",
    "    TFT_TUD = R - epsilon\n",
    "    TFT_TUC = (theta*R+S+(r-theta-1)*P)/r - epsilon\n",
    "    TFT = [TFT_ALLC,TFT_ALLD,TFT_TFT,TFT_TUD,TFT_TUC]\n",
    "    ## Trust-based Cooperate (TUC)\n",
    "    TUC_ALLC = R - (theta*epsilon)/r - (p*(r-theta)*epsilon)/r\n",
    "    TUC_ALLD = (S + (r-1)*P)/r - epsilon\n",
    "    TUC_TFT = R-(theta*epsilon)/r-(p*(r-theta)*epsilon)/r\n",
    "    TUC_TUC = R-(theta*epsilon)/r-(p*(r-theta)*epsilon)/r\n",
    "    TUC_TUD = (theta*R-theta*epsilon)/r + (1/r)*((S*(1-(1-p)**(r-theta)))/p + ((P-epsilon)*((1-p)**(r-theta)+(r-theta)*p - 1))/p)\n",
    "    TUC = [TUC_ALLC,TUC_ALLD,TUC_TFT,TUC_TUC,TUC_TUD]\n",
    "    ## Trust-based Defect (TUD)\n",
    "    TUD_ALLC = (epsilon*R+(r-epsilon)*T-theta*epsilon)/r\n",
    "    TUD_ALLD = (S+(r-1)*P)/r-epsilon\n",
    "    TUD_TFT = (theta*R+T+(r-theta-1)*P-theta*epsilon)/r\n",
    "    TUD_TUC = (theta*R-theta*epsilon)/r + (1/r)*((T*(1 - (1 - p) ** (r - theta)))/p + (P*((1-p)**(r-theta) + (r - theta)*p - 1))/p)\n",
    "    TUD_TUD = (theta*R+(r - theta) * P - theta*epsilon)/r\n",
    "    TUD = [TUD_ALLC,TUD_ALLD,TUD_TFT,TUD_TUC,TUD_TUD]\n",
    "    # Return the values as an array\n",
    "    return np.array([\n",
    "        ALLC,\n",
    "        ALLD,\n",
    "        TFT,\n",
    "        TUC,\n",
    "        TUD,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function for testing the influence of gamma and r\n",
    "def test_gamma_r(R,S,T,P,theta,p,epsilon,nb_strategies_with,nb_strategies_without,beta,Z,mu,gammas,rs):\n",
    "    # array for the results with the trust-strategies and without the trust-strategies\n",
    "    results = []\n",
    "    results_without_r = []\n",
    "    results_with_r = []\n",
    "    # go over every r in the rs\n",
    "    for r in rs:\n",
    "        # for the frequencies of strategies\n",
    "        results_with = np.zeros((nb_strategies_with,len(gammas)))\n",
    "        # for the frequency of cooperation\n",
    "        results_without = np.zeros((nb_strategies_without,len(gammas)))\n",
    "        # go over all the gammas\n",
    "        for pos in range(len(gammas)):\n",
    "            # get the gamma\n",
    "            gamma = gammas[pos]\n",
    "            # calculate the pay-offs\n",
    "            pay_off = calculate_pay_off(R,S,T,P,gamma,r,theta,p,epsilon)\n",
    "            # for all strategies\n",
    "            evolver = egt.analytical.StochDynamics(nb_strategies_with,pay_off,Z,mu)\n",
    "            # calculate the stationary distribution\n",
    "            stationary_SML = evolver.calculate_stationary_distribution(beta)\n",
    "            # store the results\n",
    "            for strategy,v in zip(range(nb_strategies_with),stationary_SML):\n",
    "                results_with[strategy][pos] = v\n",
    "            # for all strategies except TUC and TUD\n",
    "            evolver = egt.analytical.StochDynamics(nb_strategies_without, pay_off, Z,mu)\n",
    "            # calculate the stationary distribution\n",
    "            stationary_SML = evolver.calculate_stationary_distribution(beta)\n",
    "            # safe the result\n",
    "            for strategy,v in zip(range(nb_strategies_without),stationary_SML):\n",
    "                results_without[strategy][pos] = v\n",
    "        # append the results to the global result collection\n",
    "        results.append(results_with)\n",
    "        results_without_r.append(np.array([results_without[0][pos] + results_without[2][pos] for pos in range(len(gammas))]))\n",
    "        results_with_r.append(np.array([results_with[0][pos] + results_with[2][pos] + results_with[3][pos] + (results_with[4][pos] * (theta/r)) for pos in range(len(gammas))]))\n",
    "    return results,results_without_r,results_with_r\n",
    "\n",
    "# This function visualises the results\n",
    "def visualise_gamma_r(ax_strats,ax_coops,nb_strategies_with,strategies,colors_strat,nb_strategies_without,colors_trust,gammas,rs,results,results_without_trust,results_with_trust):\n",
    "    for r,ax_strat,ax_coop,result,without_trust,with_trust in zip(rs,ax_strats,ax_coops,results,results_without_trust,results_with_trust):\n",
    "        # for the frequencies of strategies\n",
    "        # Plot the line for each of the strategies\n",
    "        for pos,color_strat in zip(range(nb_strategies_with),colors_strat):\n",
    "            ax_strat.plot(gammas,result[pos],label = strategies[pos],color = color_strat)\n",
    "        # enable the legend for the graph\n",
    "        ax_strat.legend()\n",
    "        # give the x and y axis a label\n",
    "        ax_strat.set_xlabel(\"importance of the game $\\gamma$\")\n",
    "        ax_strat.set_ylabel(\"Frequency of Strategy\")\n",
    "        # put the x axis to a exponential scale\n",
    "        ax_strat.set_xscale(\"symlog\")\n",
    "        # limit the x and y axis\n",
    "        ax_strat.set_xlim(0.1,6900)\n",
    "        ax_strat.set_ylim(-0.1,1.1)\n",
    "        # for the frequency of cooperation\n",
    "        # Get the values of all the strategies that like to cooperate (without trust)\n",
    "        ax_coop.plot(gammas,without_trust,label = \"without TUC/TUD\",color = colors_trust[0])\n",
    "        # Get the values of all the strategies that like to cooperate (with trust)\n",
    "        ax_coop.plot(gammas,with_trust,label = \"with TUC/TUD\",color = colors_trust[1])\n",
    "        # color the gaps in between\n",
    "        ax_coop.fill_between(gammas, with_trust, without_trust, where=(with_trust > without_trust), color='green', alpha=0.3)\n",
    "        ax_coop.fill_between(gammas, with_trust, without_trust, where=(with_trust < without_trust), color='red', alpha=0.3)\n",
    "        # enable the legend\n",
    "        ax_coop.legend()\n",
    "        # give the x and y axis a label\n",
    "        ax_coop.set_xlabel(\"importance of the game $\\gamma$\")\n",
    "        ax_coop.set_ylabel(\"Frequency of Cooperation\")\n",
    "        # put the x axis to an exponential scale\n",
    "        ax_coop.set_xscale(\"symlog\")\n",
    "        # limit the x and y axis\n",
    "        ax_coop.set_xlim(0.1,6900)\n",
    "        ax_coop.set_ylim(-0.1,1.1)\n",
    "        # add titles\n",
    "        ax_strat.set_title(f\"r = {r}\",size = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the gammas and rs we want to test\n",
    "gammas = np.geomspace(0.1,6900,100)\n",
    "rs = np.array([20,50,100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prisoner's dilemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs = []\n",
    "for theta in [3,5,10]:\n",
    "    # run the actual experiment\n",
    "    gammas_result,gammas_without_r,gammas_with_r = test_gamma_r(R_pd,S_pd,T_pd,P_pd,theta,p,epsilon,nb_strategies_with,nb_strategies_without,beta,Z,mu,gammas,rs)\n",
    "    # create a subplot for the results\n",
    "    fig_gamma,(ax_strats_gamma,ax_coops_gamma) = plt.subplots(2,3,figsize=(18,10))\n",
    "    # add a title\n",
    "    fig_gamma.suptitle(\"Influence of $\\gamma$ and r where \" + r\"$\\theta$ = \" + f\"{theta}\",size=20)\n",
    "    # visualise the results\n",
    "    visualise_gamma_r(ax_strats_gamma,ax_coops_gamma,nb_strategies_with,strategies,colors_strat,nb_strategies_without,colors_trust,gammas,rs,gammas_result,gammas_without_r,gammas_with_r)\n",
    "    # save a figure of the results\n",
    "    fig_gamma.savefig(f'figure/idp_bigger_gamma_{theta}.png')\n",
    "    figs.append(fig_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fig in figs:\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
